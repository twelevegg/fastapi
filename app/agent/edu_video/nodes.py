import os
import json
import glob
import re
from pathlib import Path
from .state import AgentState
from .utils_file import load_and_chunk_files
from .utils_media import create_video_segment
from .rag_engine import RAGEngine
from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate

# âœ… ë¹„ìš©ì„ ì¤„ì´ë©´ì„œë„ ì¶©ë¶„íˆ ë¹ ë¥¸ ëª¨ë¸ë¡œ ë³€ê²½
llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.3)

def _clean_slide_title(title: str) -> str:
    t = str(title or "").strip()
    # "slide 0 : ", "Slide 2 -", "ìŠ¬ë¼ì´ë“œ 3:" ê°™ì€ ì ‘ë‘ì–´ ì œê±°
    t = re.sub(r"^\s*(?:slide|ìŠ¬ë¼ì´ë“œ)\s*\d+\s*[:\-â€“â€”]\s*", "", t, flags=re.IGNORECASE)
    # í˜¹ì‹œ "0: ì œëª©"ì²˜ëŸ¼ ìˆ«ìë§Œ ì˜¤ëŠ” ê²½ìš°ë„ ì œê±°
    t = re.sub(r"^\s*\d+\s*[:\-â€“â€”]\s*", "", t)

    # ê³µë°± ì •ë¦¬
    t = re.sub(r"\s+", " ", t).strip()

    # âœ… ì œëª© ê¸¸ì´ ì œí•œ (í•œ ì¤„ ê°€ë…ì„± í™•ë³´)
    # - ê°•ì˜ ìŠ¬ë¼ì´ë“œ/ì˜ìƒì—ì„œ ì œëª©ì´ ê¸¸ë©´ ë ˆì´ì•„ì›ƒì´ ê¹¨ì§€ë¯€ë¡œ ìƒí•œì„ ë‘¡ë‹ˆë‹¤.
    # - í•œê¸€ ê¸°ì¤€ ê¶Œì¥ 18~28ì, ìƒí•œ 32ì
    MAX_TITLE_LEN = 32

    if len(t) > MAX_TITLE_LEN:
        # 1) êµ¬ë¶„ì(":", "-", "|" ë“±) ì•ë¶€ë¶„ì„ ìš°ì„  ì‚¬ìš©
        splitters = [" | ", " - ", " â€“ ", " â€” ", " : ", ":", "-", "|", "â€¢"]
        for sp in splitters:
            if sp in t:
                cand = t.split(sp, 1)[0].strip()
                if cand and len(cand) <= MAX_TITLE_LEN:
                    t = cand
                    break

    if len(t) > MAX_TITLE_LEN:
        # 2) ê´„í˜¸/ëŒ€ê´„í˜¸ ì•ˆ ë¶€ê°€ì„¤ëª… ì œê±°
        t2 = re.sub(r"\s*[\(\[\{].*?[\)\]\}]\s*", " ", t).strip()
        t2 = re.sub(r"\s+", " ", t2)
        if len(t2) <= MAX_TITLE_LEN and t2:
            t = t2

    if len(t) > MAX_TITLE_LEN:
        # 3) ìµœí›„: ë§ì¤„ì„í‘œë¡œ ìë¥´ê¸°
        t = t[: MAX_TITLE_LEN - 1].rstrip() + "â€¦"

    return t

def node_initialize(state: AgentState):
    print("--- [Process] ë°ì´í„° ë¡œë“œ ë° ì²­í‚¹ ---")
    # âœ… ë‹¨ì¼ íŒŒì¼ ì…ë ¥ ì „ì œ
    input_file_path = state.get("input_file_path")
    if input_file_path and os.path.exists(str(input_file_path)):
        selected_file = str(input_file_path)
        print(f"âœ… ì…ë ¥ íŒŒì¼(ì§€ì •): {selected_file}")
        files = [selected_file]
    else:
        # âœ… ë‹¨ì¼ íŒŒì¼ ì…ë ¥ ì „ì œ(í˜„ì¬ ì‘ì—… ë””ë ‰í† ë¦¬ ìŠ¤ìº”)
        files = glob.glob("*.pdf") + glob.glob("*.pptx")
        if not files:
            print("ê²½ê³ : í•™ìŠµí•  íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (í˜„ì¬ í´ë”ì— .pdf ë˜ëŠ” .pptx 1ê°œë¥¼ ë‘ê³  ì‹¤í–‰í•´ ì£¼ì„¸ìš”.)")
            return {"is_complete": True}

        # ì—¬ëŸ¬ ê°œê°€ ìˆìœ¼ë©´ ìµœì‹  íŒŒì¼ 1ê°œë§Œ ì‚¬ìš©
        files = sorted(files, key=lambda p: os.path.getmtime(p), reverse=True)
        selected_file = files[0]
        if len(files) > 1:
            print(f"âš ï¸ ì—¬ëŸ¬ íŒŒì¼ì´ ê°ì§€ë˜ì–´ ìµœì‹  íŒŒì¼ 1ê°œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤: {selected_file}")
        else:
            print(f"âœ… ì…ë ¥ íŒŒì¼: {selected_file}")
    if len(files) > 1:
        print(f"âš ï¸ ì—¬ëŸ¬ íŒŒì¼ì´ ê°ì§€ë˜ì–´ ìµœì‹  íŒŒì¼ 1ê°œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤: {selected_file}")
    else:
        print(f"âœ… ì…ë ¥ íŒŒì¼: {selected_file}")
    
    knowledge_base = load_and_chunk_files([selected_file])
    return {
        "knowledge_base": knowledge_base,
        "unlearned_ids": [u['id'] for u in knowledge_base],
        "weak_ids": [],
        "mastered_ids": [],
        "is_complete": False
    }

def node_curriculum_manager(state: AgentState):
    print("--- [Process] ë‹¨ì¼ íŒŒì¼ ì»¤ë¦¬í˜ëŸ¼ êµ¬ì„± ---")
    # ë‹¨ì¼ íŒŒì¼ì´ë¯€ë¡œ íŒŒì¼ íƒ€ì…ë³„ 3:7 ìƒ˜í”Œë§ ëŒ€ì‹ , ë‚¨ì€ ì²­í¬ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ë°°ì¹˜ êµ¬ì„±
    order = state.get("_selection_order", "weak_first")
    if order == "unlearned_first":
        remaining_ids = state.get('unlearned_ids', []) + state.get('weak_ids', [])
    else:
        remaining_ids = state.get('weak_ids', []) + state.get('unlearned_ids', [])
    remaining_ids = [i for i in remaining_ids if i in {u['id'] for u in state['knowledge_base']}]

    target_size = 14  # 7~10ë¶„ ë¶„ëŸ‰ì„ ìœ„í•œ ì²­í¬ ìˆ˜(ëŒ€ëµ)
    current_batch_ids = remaining_ids[:target_size]

    if not current_batch_ids:
        return {"is_complete": True}
    return {"current_batch_ids": current_batch_ids}

def node_content_creator(state: AgentState):
    print(f"--- [Process] ë§ì¶¤í˜• êµìœ¡ ì‹œí€€ìŠ¤ ìƒì„± (ì´ {len(state['current_batch_ids'])}ê°œ ì²­í¬) ---")
    
    target_ids = state['current_batch_ids']
    chunks = [u['content'] for u in state['knowledge_base'] if u['id'] in target_ids]
    chunk_groups = [chunks[i:i+2] for i in range(0, len(chunks), 2)]
    
    full_context = ""
    for idx, group in enumerate(chunk_groups):
        full_context += f"\n[Slide {idx+1} Data]\n" + "\n".join(group)

    prompt = ChatPromptTemplate.from_template(
        """
        ë‹¹ì‹ ì€ ê¸°ì—… êµìœ¡ ì „ë¬¸ ê°•ì‚¬ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ìë£Œë¥¼ ë¶„ì„í•˜ì—¬ 'ë¸Œëœë“œ'ë¥¼ ì‹ë³„í•˜ê³  ìì—°ìŠ¤ëŸ¬ìš´ ê°•ì˜ ì‹œí€€ìŠ¤ë¥¼ ë§Œë“œì„¸ìš”.

        [ì§€ì‹œì‚¬í•­]
        1. **ë¸Œëœë“œ ì‹ë³„**: ìë£Œì— ë‚˜ì˜¤ëŠ” ê¸°ì—…ì´ë‚˜ í†µì‹ ì‚¬ ì´ë¦„(ì˜ˆ: SKT, KT, LG U+ ë“±)ì„ ì •í™•íˆ íŒŒì•…í•˜ì—¬ 'brand' í•„ë“œì— ë„£ìœ¼ì„¸ìš”. ë§Œì•½ ëª…ì‹œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¹ˆì¹¸ìœ¼ë¡œ ë†”ë‘ì„¸ìš”.
        2. **ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°**: Slide 1ë§Œ ì¸ì‚¬ë¥¼ í•˜ê³ , Slide 2ë¶€í„°ëŠ” "ë‹¤ìŒìœ¼ë¡œ", "ì—°ê²°í•´ì„œ ì„¤ëª…ë“œë¦¬ë©´" ë“± ìì—°ìŠ¤ëŸ¬ìš´ ì „í™˜ì–´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”. ì ˆëŒ€ ë§¤ ìŠ¬ë¼ì´ë“œë§ˆë‹¤ ì¸ì‚¬ë¥¼ ë°˜ë³µí•˜ì§€ ë§ˆì„¸ìš”.
        3. **ë‚´ìš© í’ì„±í•¨**: ê° ìŠ¬ë¼ì´ë“œ(summary)ëŠ” ë°˜ë“œì‹œ 5ê°œ ì´ìƒì˜ ë¶ˆë ›í¬ì¸íŠ¸ë¡œ ì‘ì„±í•˜ì„¸ìš”. ìë£Œê°€ ë¶€ì¡±í•˜ë©´ í•´ë‹¹ ê°œë…ì— ëŒ€í•œ 'ìƒë‹´ ì˜ˆì‹œ'ë‚˜ 'í˜„ì¥ Q&A'ë¥¼ ì¶”ê°€í•˜ì—¬ ë¶„ëŸ‰ì„ ì±„ìš°ì„¸ìš”.
        4. **ëŒ€ë³¸ ë¶„ëŸ‰**: ìŠ¬ë¼ì´ë“œë‹¹ 1ë¶„ ë‚´ì™¸(150ì ì´ìƒ)ì˜ ìƒì„¸ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.
        5. **ì œëª© ê·œì¹™**: titleì€ í•œ ì¤„ë¡œ ë³´ì´ë„ë¡ **32ì ì´ë‚´**ë¡œ ì‘ì„±í•˜ê³ , í•µì‹¬ í‚¤ì›Œë“œ ì¤‘ì‹¬ìœ¼ë¡œ ì§§ê²Œ ë§Œë“œì„¸ìš”. (ê¸´ ë¶€ê°€ì„¤ëª…/ì˜ˆì‹œëŠ” summaryë¡œ ì˜®ê¸°ê¸°)

        [ìë£Œ]
        {context}

        í˜•ì‹: JSON ë¦¬ìŠ¤íŠ¸ [{{ "brand": "ì‹ë³„ëœì´ë¦„", "title": "ì œëª©", "summary": "ë‚´ìš©1\\në‚´ìš©2...", "text": "ëŒ€ë³¸..." }}]
        """
    )
    
    response = (prompt | llm).invoke({"context": full_context})
    
    try:
        clean_res = response.content.replace("```json", "").replace("```", "").strip()
        script_segments = json.loads(clean_res)
        if isinstance(script_segments, list):
            for seg in script_segments:
                if isinstance(seg, dict) and "title" in seg:
                    seg["title"] = _clean_slide_title(seg.get("title", ""))
    except:
        script_segments = [{"brand": "Education", "title": "êµìœ¡ ì„¸ì…˜", "summary": "ë‚´ìš© ìš”ì•½", "text": response.content}]

    session_idx = len(state.get('mastered_ids', []))
    video_filename = f"edu_session_{session_idx}.mp4"

    # âœ… PPT ì—†ì´ ì´ë¯¸ì§€ ê¸°ë°˜ìœ¼ë¡œ ë°”ë¡œ ì˜ìƒë§Œ ìƒì„±
    create_video_segment(script_segments, output_filename=video_filename)
    
    return {
        "current_video_path": video_filename,
        "current_ppt_path": None,
        "current_script": str(script_segments)
    }

# --- 4. í€´ì¦ˆ ìƒì„± ë…¸ë“œ ---
def node_quiz_generator(state: AgentState):
    print("--- [Process] í€´ì¦ˆ ìƒì„± ---")
    
    target_contents = [u['content'] for u in state['knowledge_base'] if u['id'] in state['current_batch_ids']]
    context_text = "\n".join(target_contents)
    
    # ë¬¸ì œ ìˆ˜: ë°°ì¹˜ í¬ê¸°ì— ë¹„ë¡€ (ì•½ 2~3ë°°ìˆ˜)
    num_questions = 10
    
    prompt = ChatPromptTemplate.from_template(
        """
        ì•„ë˜ êµìœ¡ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ {num}ê°œì˜ 4ì§€ ì„ ë‹¤í˜• í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.
        í†µì‹ ì‚¬ ì—…ë¬´ì™€ ê´€ë ¨ëœ ë‰˜ì•™ìŠ¤ë¥¼ ì‚´ë ¤ì£¼ì„¸ìš”.
        ì¶œë ¥ í¬ë§·(JSON List): [{{ "question": "ë¬¸ì œ", "options": ["ë³´ê¸°1", "ë³´ê¸°2", "ë³´ê¸°3", "ë³´ê¸°4"], "correct_answer": ì •ë‹µì¸ë±ìŠ¤(0-3), "related_chunk_index": ê´€ë ¨ëœ_ë‚´ìš©_ìˆœì„œ_ì¸ë±ìŠ¤ }}]
        
        ë‚´ìš©:
        {context}
        """
    )
    chain = prompt | llm
    response = chain.invoke({"context": context_text, "num": num_questions})
    
    try:
        quiz_data = json.loads(response.content.replace("```json", "").replace("```", "").strip())
    except:
        quiz_data = [] # ì—ëŸ¬ ì²˜ë¦¬ ìƒëµ
        
    return {"current_quiz": quiz_data}

#  ì±„ì 

def node_grader(state: AgentState):
    print("\n" + "="*20 + " [ì±„ì  ë° ìƒì„¸ í”¼ë“œë°± ì‹œì‘] " + "="*20)
    
    quiz_list = state['current_quiz']
    user_answers = state['user_answers']
    knowledge_base = state['knowledge_base']
    
    rag = RAGEngine(knowledge_base, collection_name=str(state.get("job_id","edu_rag")), persist_directory=state.get("persist_directory"))
    
    score = 0
    feedback_details = []
    wrong_chunk_ids = set()
    mastered_ids_in_session = []

    for i, (q, u_ans) in enumerate(zip(quiz_list, user_answers)):
        is_correct = (q['correct_answer'] == u_ans)
        
        # RAGë¥¼ í†µí•´ ê·¼ê±° ìë£Œ í™•ë³´
        search_query = f"{q['question']} {q['options'][q['correct_answer']]}"
        contexts = rag.get_detailed_context(search_query)

        # ì»¨í…ìŠ¤íŠ¸ë¥¼ LLMì— ì£¼ê¸° ì¢‹ê²Œ ê°„ë‹¨íˆ í¬ë§·íŒ…
        def _fmt_ctx(c):
            src = Path(str(c.get('source', ''))).name
            pg = c.get('page')
            pg_txt = f"{pg}P" if pg not in (None, "?") else "?P"
            excerpt = str(c.get('content', '')).replace("\n", " ").strip()
            if len(excerpt) > 260:
                excerpt = excerpt[:260] + "..."
            return f"- {src} {pg_txt}: {excerpt}"
        formatted_contexts = "\n".join([_fmt_ctx(c) for c in contexts])
        
        # LLMì—ê²Œ ìƒì„¸ í•´ì„¤ ìš”ì²­
        explanation_prompt = f"""
ë‹¹ì‹ ì€ í†µì‹ ì‚¬ CS êµìœ¡ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì•„ë˜ í€´ì¦ˆ ë¬¸ì œì— ëŒ€í•œ í”¼ë“œë°±ì„ **ë°˜ë“œì‹œ ì§€ì •ëœ í˜•ì‹**ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.

[ë¬¸ì œ]: {q['question']}
[ì •ë‹µ]: {q['options'][q['correct_answer']]}
[ì‚¬ìš©ì ë‹µë³€]: {q['options'][u_ans] if isinstance(u_ans, int) else u_ans}
[ê²°ê³¼]: {"ì •ë‹µ" if is_correct else "ì˜¤ë‹µ"}

[ì°¸ê³ ìë£Œ í›„ë³´]:
{formatted_contexts}

[ì¶œë ¥ í˜•ì‹(ë°˜ë“œì‹œ ì¤€ìˆ˜)]:
í•´ì„¤: (ì •ë‹µì¸ ì´ìœ ë¥¼ 2~4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…. ì˜¤ë‹µì´ë©´ ì™œ í—·ê°ˆë ¸ëŠ”ì§€ë„ 1ë¬¸ì¥ ì¶”ê°€)
ì°¸ê³ ìë£Œ: (ë°˜ë“œì‹œ 'íŒŒì¼ëª…'ê³¼ 'í˜ì´ì§€(P)'ë¥¼ í¬í•¨í•´ì„œ 1~2ê°œë§Œ ê³ ë¥´ê¸°. ì•„ë˜ì²˜ëŸ¼ ì‘ì„±)
 - ì°¸ê³ ìë£Œ <íŒŒì¼ëª…> <í˜ì´ì§€>Pë¥¼ í™•ì¸í•´ë³´ë©´ "<í•µì‹¬ ê·¼ê±° êµ¬ì ˆ>" ë¼ê³  ë˜ì–´ ìˆì–´ìš”.
"""
        
        explanation_res = llm.invoke(explanation_prompt).content
        
        # í”¼ë“œë°± ì €ì¥
        result_text = "âœ… [ì •ë‹µ]" if is_correct else "âŒ [ì˜¤ë‹µ]"
        feedback_details.append(f"{i+1}ë²ˆ ë¬¸ì œ: {result_text}\n{explanation_res}\n" + "-"*50)

        if is_correct:
            score += 1
            # ë§ì€ ë¬¸ì œì™€ ì—°ê²°ëœ ì§€ì‹ ë‹¨ìœ„ ID ì €ì¥ (chunk_indexê°€ ìˆë‹¤ê³  ê°€ì •)
            idx = q.get('related_chunk_index', 0)
            if idx < len(state['current_batch_ids']):
                mastered_ids_in_session.append(state['current_batch_ids'][idx])
        else:
            idx = q.get('related_chunk_index', 0)
            if idx < len(state['current_batch_ids']):
                wrong_chunk_ids.add(state['current_batch_ids'][idx])

    final_score = (score / len(quiz_list)) * 100 if quiz_list else 0
    
    # í™”ë©´ ì¶œë ¥
    for feedback in feedback_details:
        print(feedback)
        
    print(f"\nğŸ¯ ìµœì¢… ì ìˆ˜: {final_score}ì ")

    # âœ… ìƒíƒœ ì—…ë°ì´íŠ¸(weak/unlearned/mastered)
    new_mastered = list(dict.fromkeys(state.get('mastered_ids', []) + mastered_ids_in_session))
    new_weak = list(dict.fromkeys(state.get('weak_ids', []) + list(wrong_chunk_ids)))
    # ë°°ì¹˜ì— í¬í•¨ëœ mastered/weakëŠ” unlearnedì—ì„œ ì œê±°
    to_remove = set(mastered_ids_in_session) | set(wrong_chunk_ids)
    new_unlearned = [i for i in state.get('unlearned_ids', []) if i not in to_remove]

    return {
        "mastered_ids": new_mastered,
        "weak_ids": new_weak,
        "unlearned_ids": new_unlearned,
        "quiz_score": final_score,
        "quiz_feedback": "\n\n".join(feedback_details)
    }